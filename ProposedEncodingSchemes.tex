\chapter{Proposed Encoding Scheme}

Garg, Gentry and Halevi constructed a Graded Encoding Scheme based on ideal lattices, in \cite{GGH13}. Their construction was the first candidate to approximate multilinear maps, therefore had a tremendous impact in the world of cryptography. The current chapter intends to present the system designed by the three aforementioned authors, in an in-depth manner. 

\section{Overview}

To start with, the ring $R$ denotes the cyclotomic polynomial ring $\bZ[X]/(X^n +1)$, for some integer $n$ - power of two. The ring $R$ is often considered to be the lattice $\bZ^n$, because a correspondence between the two structures is obvious. Also, $g \in R$ is a short ring element and $\id = \langle g \rangle$ is the principal ideal generated by $g$. Additionaly, an element $\zz$ is extracted randomly in $R_q$. \\

The elements to be encoded by the scheme are the equivalence classes (or \textbf{cosets}) of the quotient ring $QR = R / \id$, denoted by $\eh$, for some $e \in R$. \\

A level-zero encoding of a coset $\eh$ is a short vector in that coset. The existence of a small vector in any coset is assured by the fact that $g$ is a short element, therefore the basis $B(g) = \{g, Xg,...,X^{n-1}g\}$ has all elements small - only circular permutations of the vector $g$, eventually with a changed sign. Hence, the fundamental domain itself of $B(g)$ is small and because for any $e \in R$, there exists an element $e_g \in \mathcal{F}(B(g))$ such that $e_g \in \eh$, the result follows immediately.\\

For any $i \in \{1,2...,k\}$, the set of all level-$i$ encodings of a coset $\eh$ is $S_i^{\eh} = \big\{ \frac{c}{\zz^i}\in R_q : c \in eh, ||c|| < q^{1/8}\big\}$. The value $||c||$ will be referred to as the \textbf{noise level} of the encoding.\\

\section{Efficient Procedures}

The procedures to be presented are a specific case of the efficient procedures introduced in Subsection 1.4.1. Thus, in this section only the implementation of the mentioned functions will be exposed, as in \cite{GGH13}, with a high-level algorithm exposed in the beginning of every procedure, and the in-depth explanation afterwards. Note that $R$ may be identified by $\bZ^n$, and $R_q$ by $\bZ_q^n$. Also, $K$ denotes the field $\bQ[X]/(X^{n}+1)$.\\

\begin{enumerate}[label=(\alph*)]
	\item \textbf{Instance generation}: (params, \pzt) $\la$ InstGen($1^\lambda, 1^k$).
	
	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
		\begin{center}
			\textbf{InstGen($1^\lambda, 1^k$)}
		\end{center}
		\begin{algorithmic}[1]
			\State Choose $g \la \mathcal{D}_{\bZ^n, \sigma}$ (encoding of the generator, element kept \textbf{private}).
			\Statex
			
			\State Choose $\zz\la R_q$ (encoding of a \textbf{private} element, used for encoding elements on level higher than 0).
			\Statex
			
			\State Choose $a \la \mathcal{D}_{\hat{1}, \sigma''}$, then compute a \textbf{public} level-one representation of $\hat{1}$, $\textbf{y} = \big[\frac{\textbf{a}}{\textbf{z}}\big]_q$.
			\Statex
			
			\State Choose $\textbf{b}_i \la \mathcal{D}_{\hat{0}, \sigma'''}, \forall i \in \{1,2,..., m\}$ and compute $\xx_i = \big[\frac{\textbf{b}_i}{\textbf{z}}\big]_q, \forall i \in \{1,2,..., m\}$, \textbf{public} level-one representations of $\hat{0}$. Also, set  $X = (\xx_1 | \xx_2 |...|\xx_m)^T$.
			\Statex
			
			\State Choose \pzt $\la R_q$ and $s \la \bZ.$ 
			\Statex
			\State \textbf{Output}: params = ($n, q, \textbf{y}, \xx_1,\xx_2,..,\xx_m, s$), \pzt.
		\end{algorithmic}
	\end{tcolorbox}

	\begin{enumerate}[label=\arabic*:]
		\item The uniform extraction of $g$ from the spherical Gaussian distribution $\mathcal{D}_{\bZ^n, \sigma}$, with $\sigma = \sqrt{\lambda n}$, is performed repeatedly, until the following conditions are met:
		
		\begin{itemize}
			\item $||g|| \leq \sigma \sqrt{n}$ and $g$ is invertible in $R_q$;
			\item $g^{-1}$ is a short vector;
			\item $\textbf{N}(g)$ is a prime $\geq 2^{O(n)}$, where $\textbf{N}(g)$ denotes the norm of the ideal $\langle g \rangle$, as defined in \cite{Gar15}, chapter 5.
		\end{itemize}
		
		The last condition implies that $\id = \langle g \rangle$ is a \textbf{prime ideal}. Also, \textbf{Lemma 6.1} from \cite{Gar15} proves that the algorithm above completes in polinomially many trials.
		
		
		\item $\zz$ is chosen uniformly from $R_q$, thus with overwhelming probability is not "small". Using \cite{Gar15} (\textit{Lemma 5.20}), it follows that with overwhelming probability, $\zz$ is invertible in $R_q$.
		
		\item Parameters $\textbf{y}$ and $X$ will show their usefulness during the \textbf{higher-level encoding} procedure. Also, {\pzt} is used as a zero-testing parameter, while $s$ is used as a seed for a strong randomness extractor.
	\end{enumerate}


%%%%%%%%%%%%%%%% Finished Instance Generation %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Sampling level-zero encodings}: $d \la$ \textbf{samp}(params).

	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		\textbf{samp}(params)
	\end{center}
	\begin{algorithmic}[1]
		\State Choose \textbf{$d$} $\la \mathcal{D}_{\bZ^n, \sigma'}$.
		\Statex
		\State \textbf{Output}: \textbf{d}.
	\end{algorithmic}
\end{tcolorbox}

	It can be proved that, if $\sigma' \geq \sqrt{\lambda n}||g||$, then the distribution ($\textbf{d}\mod\id$) is statistically close to the uniform distribution over ($\bZ^n \mod \id$). Therefore, the coset to be sampled is close to uniform.
	
	To prove it, firstly it can be stated that, because $g \in \id$, then $\lambda_1(\id) \leq ||g||$. Also, knowing that $\id$ is an ideal of the $(2n)^{th}$ cyclotomic ring, with $n$ a power of two, it follows from \textbf{Proposition 5} that $\lambda_n(L) = \lambda_1(L)$. Corroborating the two results, it results that $\lambda_n(L)\leq ||g||$. Therefore, applying \textbf{Lemma 1}, it follows that:
	
	\begin{center}
		$\eta_{2^{-\lambda}}(\id) \leq \sqrt{\frac{\ln(2n(1 + 2 ^\lambda))}{\pi}} \cdot \lambda_n(L) \leq  \eta_{2^{-\lambda}}(\id) \leq \sqrt{\frac{\ln(2n(1 + 2 ^\lambda))}{\pi}} \cdot ||g|| \leq \sqrt{n\lambda} ||g||$.
	\end{center}

Since $\sigma' \geq \sqrt{\lambda n}||g||$, it is obvious that $\sigma' \geq \eta_{2^{-\lambda}}(\id)$, therefore the proof is complete. \\

Also, the size of \textbf{d} is bounded by $\sigma'\sqrt{n}$, result proved by \textbf{Lemma 2}.

\item \textbf{Encodings at higher levels:} $\textbf{u}_i \la \text{enc(params,}i, \textbf{d})$.

	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		$\text{\textbf{enc}(params,}i, \textbf{d})$
	\end{center}
	\begin{algorithmic}[1]
		\If {$i == 1$}
		\State Choose $\textbf{r}\la \mathcal{D}_{\bZ^n, \sigma^*}$.
		\State Set $\textbf{u}_i = \big[ \frac{\textbf{yd}}{\textbf{z}} + X^T\textbf{r}\big]_q$.
		\Else
		\State Set $\textbf{u}_i = [\textbf{d}\cdot \textbf{y}^i]_q$.
		\State \textbf{Output:} \textbf{u}$_i$.
		\EndIf
	\end{algorithmic}
\end{tcolorbox}

The necessity of publishing a level-one representation of an element is obvious, from the inherent structure of the construction. The "lifting" of a representation, from a lower level to a higher one, may be performed only using another representation of an element, on a higher level.\\

In order to preserve the element to be encoded and to change only the level of encoding, the public element $\textbf{y}$ is an encryption of element $\hat{1}$ - the neutral element at multiplication in $QR$. Also, because $\textbf{y}$ is a level-one encoding, multiplying another element by it results in "lifting" the representation only one level. Therefore, combining the two arguments, it follows that multiplying any level-$i$ representation of an element $\alpha \in QR$ by $\textbf{y}$, it results a level-$(i+1)$ representation of $\alpha$.\\

More formally, given a level-zero encoding $\textbf{d}$, then the level-one representation of \textbf{d} is $\textbf{u}_1 = [\textbf{dy}]_q = \big[ \frac{\textbf{\textbf{da}}}{\textbf{z}} \big]$, where $a \la \mathcal{D}_{\hat{1}, \sigma''}$, therefore an element $\textbf{x} \in \id$ exists such that $a = 1 + \textbf{x}$. Then, $\textbf{d}a = \textbf{d} + \textbf{dx}$, with $\textbf{x} \in \id$, so $\textbf{d}a \in \hat{\textbf{d}}$. Also, $||\textbf{d}a|| \leq ||d|| \cdot ||a|| \cdot \sqrt{n}$, which is a polynomial in $n$. Thus, $\textbf{u}_1 = [\textbf{dy}]_q$ is a valid level-one encoding of $\textbf{d}$. \\

Generally, in order to generate a level-$i$ encoding of \textbf{d}, one can simply multiply \textbf{d} by $\textbf{y}^i$, and get: $\textbf{u}_i = [\textbf{dy}^i]_q = \big[ \frac{\textbf{d}a^i}{\zz^i} \big]$. It can be seen that, for a similar reason as above, $\textbf{d}a^i \in \hat{\textbf{d}}$ and also $||\textbf{d}a^i|| \leq ||\textbf{d}|| \cdot ||a|| \cdot n^{i/2}$, therefore $\textbf{u}_i$ is a valid level-$i$ encoding of \textbf{d}.\\

Usually, the applications of Graded Encoding System require that a level-one representation of an element to be made public, without the possibility to recover a level-zero representation of that element. Thus, the process of generating $\textbf{u}_1$ requires a more extensive technique. That is because in the setting above, one can easily recover $\textbf{d}$ by simply dividing $\textbf{u}_1$ to \textbf{y} in $R_q$, which is unacceptable. \\

Therefore, every level-one encoding of an element is randomized, in order to prevent easy recovery of plain-text. The procedure is as follows: given $\textbf{d}$, a level-zero representation of an element, the first step is to extract an element $\textbf{r}$ from the spherical discrete Gaussian distribution $\mathcal{D}_{\bZ^m, \sigma^*}$, for a large enough $\sigma^*$. Then, the result is:

\begin{center}
	$\textbf{u}_1 = [\textbf{yd} + X^T\textbf{r}]_q = \Bigg[\textbf{yd} + \displaystyle{\sum_{i = 1}^{m} \textbf{x}_i \cdot r_i} \Bigg]_q = \Bigg[ \frac{a\textbf{d} + \sum_{i = 1}^{m} r_i \textbf{b}_i}{\zz} \Bigg]_q$.
\end{center}

Knowing that $b_i \in \hat{0}, \forall i\in \{1,2,..,m\}$ and that $a \in \hat{1}$, it easily follows that $a\textbf{d} + \sum_{i = 1}^{m} r_i \textbf{b}_i \in \hat{\textbf{d}}$. Also, the length of the numerator is upper-bounded by $\sigma^*\cdot$poly$(m,n)$. Also, if the parameters $\textbf{b}_i$ are chosen from a fairly wide enough spherical Gaussian distribution, then from \textbf{Theorem 4} it follows that the distribution of $B\textbf{r}$ is close to a wide ellipsoidal Gaussian. Hence, the distribution of $a\textbf{d} + B\textbf{r}$ is nearly independent of $a\textbf{d}$, so the encoding is truly randomized. 

\textbf{Remark 8.} \textit{Randomization may be performed at any level, not only the first one. Besides, other versions of Graded Encoding Schemes(e.g. \cite{CLT13}) include a procedure for randomization at level-one, denoted \textbf{reRand}. The current setting is more restrictive, but has the advantage that it realizes a randomization for every level-one encoding of an element, reducing the implementation errors due to negligence.}
\end{enumerate}