\chapter{Proposed Encoding Scheme}

Garg, Gentry and Halevi constructed a Graded Encoding Scheme based on ideal lattices, in \cite{GGH13}. Their construction was the first candidate to approximate multilinear maps, therefore had a tremendous impact in the world of cryptography. The current chapter intends to present the system designed by the three aforementioned authors, in an in-depth manner. 

\section{Overview}

To start with, the ring $R$ denotes the cyclotomic polynomial ring $\bZ[X]/(X^n +1)$, for some integer $n$ - power of two. The ring $R$ is often considered to be the lattice $\bZ^n$, because a correspondence between the two structures is obvious. Also, $g \in R$ is a short ring element and $\id = \langle g \rangle$ is the principal ideal generated by $g$. Additionaly, an element $\zz$ is extracted randomly in $R_q$. \\

The elements to be encoded by the scheme are the equivalence classes (or \textbf{cosets}) of the quotient ring $QR = R / \id$, denoted by $\eh$, for some $e \in R$. \\

A level-zero encoding of a coset $\eh$ is a short vector in that coset. The existence of a small vector in any coset is assured by the fact that $g$ is a short element, therefore the basis $B(g) = \{g, Xg,...,X^{n-1}g\}$ has all elements small - only circular permutations of the vector $g$, eventually with a changed sign. Hence, the fundamental domain itself of $B(g)$ is small and because for any $e \in R$, there exists an element $e_g \in \mathcal{F}(B(g))$ such that $e_g \in \eh$, the result follows immediately.\\

For any $i \in \{1,2...,k\}$, the set of all level-$i$ encodings of a coset $\eh$ is $S_i^{\eh} = \big\{ \frac{c}{\zz^i}\in R_q : c \in eh, ||c|| < q^{1/8}\big\}$. The value $||c||$ will be referred to as the \textbf{noise level} of the encoding.\\

\section{Efficient Procedures}

The procedures to be presented are a specific case of the efficient procedures introduced in Subsection 1.4.1. Thus, in this section only the implementation of the mentioned functions will be exposed, as in \cite{GGH13}, with a high-level algorithm exposed in the beginning of every procedure, and the in-depth explanation afterwards. Note that $R$ may be identified by $\bZ^n$, and $R_q$ by $\bZ_q^n$. Also, $K$ denotes the field $\bQ[X]/(X^{n}+1)$.\\

\begin{enumerate}[label=(\alph*)]
	\item \textbf{Instance generation}: (params, \pzt) $\la$ InstGen($1^\lambda, 1^k$).
	
	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
		\begin{center}
			\textbf{InstGen($1^\lambda, 1^k$)}
		\end{center}
		\begin{algorithmic}[1]
			\State Choose $g \la \mathcal{D}_{\bZ^n, \sigma}$ (encoding of the generator, element kept \textbf{private}).
			\Statex
			
			\State Choose $\zz\la R_q$ (encoding of a \textbf{private} element, used for encoding elements on level higher than 0).
			\Statex
			
			\State Choose $a \la \mathcal{D}_{\hat{1}, \sigma''}$, then compute a \textbf{public} level-one representation of $\hat{1}$, $\textbf{y} = \big[\frac{\textbf{a}}{\textbf{z}}\big]_q$.
			\Statex
			
			\State Choose $\textbf{b}_i \la \mathcal{D}_{\hat{0}, \sigma'''}, \forall i \in \{1,2,..., m\}$ and compute $\xx_i = \big[\frac{\textbf{b}_i}{\textbf{z}}\big]_q, \forall i \in \{1,2,..., m\}$, \textbf{public} level-one representations of $\hat{0}$. Also, set  $X = (\xx_1 | \xx_2 |...|\xx_m)^T$.
			\Statex
			
			\State Choose $\textbf{h} \la \mathcal{D}_{\bZ^n, \sqrt{q}}$ such that $h \notin \id$, then compute the zero-testing parameter \pzt$=\big[\frac{\textbf{hz}^k}{\textbf{g}}\big]_q$.
			\Statex
			
			\State Choose $s \la \bZ$.
			\Statex
			
			\State \textbf{Output}: params = ($n, q, \textbf{y}, \xx_1,\xx_2,..,\xx_m, s$), \pzt.
		\end{algorithmic}
	\end{tcolorbox}

	\begin{enumerate}[label=\arabic*:]
		\item The uniform extraction of $g$ from the spherical Gaussian distribution $\mathcal{D}_{\bZ^n, \sigma}$, with $\sigma = \sqrt{\lambda n}$, is performed repeatedly, until the following conditions are met:
		
		\begin{itemize}
			\item $||g|| \leq \sigma \sqrt{n}$ and $g$ is invertible in $R_q$;
			\item $g^{-1}$ is a short vector;
			\item $\textbf{N}(g)$ is a prime $\geq 2^{O(n)}$, where $\textbf{N}(g)$ denotes the norm of the ideal $\langle g \rangle$, as defined in \cite{Gar15}, chapter 5.
		\end{itemize}
		
		The last condition implies that $\id = \langle g \rangle$ is a \textbf{prime ideal}. Also, \textbf{Lemma 6.1} from \cite{Gar15} proves that the algorithm above completes in polinomially many trials.
		
		
		\item $\zz$ is chosen uniformly from $R_q$, thus with overwhelming probability is not "small". Using \cite{Gar15} (\textit{Lemma 5.20}), it follows that with overwhelming probability, $\zz$ is invertible in $R_q$.
		
		\item Parameters $\textbf{y}$ and $X$ will show their usefulness during the \textbf{higher-level encoding} procedure. Also, {\pzt} is used as a zero-testing parameter, while $s$ is used as a seed for a strong randomness extractor.\\
	\end{enumerate}


%%%%%%%%%%%%%%%% Finished Instance Generation %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Sampling level-zero encodings}: $d \la$ \textbf{samp}(params).

	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		\textbf{samp}(params)
	\end{center}
	\begin{algorithmic}[1]
		\State Choose \textbf{$d$} $\la \mathcal{D}_{\bZ^n, \sigma'}$.
		\Statex
		\State \textbf{Output}: \textbf{d}.
	\end{algorithmic}
\end{tcolorbox}

	It can be proved that, if $\sigma' \geq \sqrt{\lambda n}||g||$, then the distribution ($\textbf{d}\mod\id$) is statistically close to the uniform distribution over ($\bZ^n \mod \id$). Therefore, the coset to be sampled is close to uniform.
	
	To prove it, firstly it can be stated that, because $g \in \id$, then $\lambda_1(\id) \leq ||g||$. Also, knowing that $\id$ is an ideal of the $(2n)^{th}$ cyclotomic ring, with $n$ a power of two, it follows from \textbf{Proposition 5} that $\lambda_n(L) = \lambda_1(L)$. Corroborating the two results, it results that $\lambda_n(L)\leq ||g||$. Therefore, applying \textbf{Lemma 1}, it follows that:
	
	\begin{center}
		$\eta_{2^{-\lambda}}(\id) \leq \sqrt{\frac{\ln(2n(1 + 2 ^\lambda))}{\pi}} \cdot \lambda_n(L) \leq  \eta_{2^{-\lambda}}(\id) \leq \sqrt{\frac{\ln(2n(1 + 2 ^\lambda))}{\pi}} \cdot ||g|| \leq \sqrt{n\lambda} ||g||$.
	\end{center}

Since $\sigma' \geq \sqrt{\lambda n}||g||$, it is obvious that $\sigma' \geq \eta_{2^{-\lambda}}(\id)$, therefore the proof is complete. \\

Also, the size of \textbf{d} is bounded by $\sigma'\sqrt{n}$, result proved by \textbf{Lemma 2}.\\

%%%%%%%%%%%%%%%% Finished Sampling Procedure %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Encodings at higher levels:} $\textbf{u}_i \la \text{enc(params,}i, \textbf{d})$.

	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		$\text{\textbf{enc}(params,}i, \textbf{d})$
	\end{center}
	\begin{algorithmic}[1]
		\If {$i == 1$}
		\State Choose $\textbf{r}\la \mathcal{D}_{\bZ^n, \sigma^*}$.
		\State Set $\textbf{u}_i = \big[ \frac{\textbf{yd}}{\textbf{z}} + X^T\textbf{r}\big]_q$.
		\Else
		\State Set $\textbf{u}_i = [\textbf{d}\cdot \textbf{y}^i]_q$.
		\State \textbf{Output:} \textbf{u}$_i$.
		\EndIf
	\end{algorithmic}
\end{tcolorbox}

The necessity of publishing a level-one representation of an element is obvious, from the inherent structure of the construction. The "lifting" of a representation, from a lower level to a higher one, may be performed only using another representation of an element, on a higher level.\\

In order to preserve the element to be encoded and to change only the level of encoding, the public element $\textbf{y}$ is an encryption of element $\hat{1}$ - the neutral element at multiplication in $QR$. Also, because $\textbf{y}$ is a level-one encoding, multiplying another element by it results in "lifting" the representation only one level. Therefore, combining the two arguments, it follows that multiplying any level-$i$ representation of an element $\alpha \in QR$ by $\textbf{y}$, it results a level-$(i+1)$ representation of $\alpha$.\\

More formally, given a level-zero encoding $\textbf{d}$, then the level-one representation of \textbf{d} is $\textbf{u}_1 = [\textbf{dy}]_q = \big[ \frac{\textbf{\textbf{da}}}{\textbf{z}} \big]$, where $a \la \mathcal{D}_{\hat{1}, \sigma''}$, therefore an element $\textbf{x} \in \id$ exists such that $a = 1 + \textbf{x}$. Then, $\textbf{d}a = \textbf{d} + \textbf{dx}$, with $\textbf{x} \in \id$, so $\textbf{d}a \in \hat{\textbf{d}}$. Also, $||\textbf{d}a|| \leq ||d|| \cdot ||a|| \cdot \sqrt{n}$, which is a polynomial in $n$. Thus, $\textbf{u}_1 = [\textbf{dy}]_q$ is a valid level-one encoding of $\textbf{d}$. \\

Generally, in order to generate a level-$i$ encoding of \textbf{d}, one can simply multiply \textbf{d} by $\textbf{y}^i$, and get: $\textbf{u}_i = [\textbf{dy}^i]_q = \big[ \frac{\textbf{d}a^i}{\zz^i} \big]$. It can be seen that, for a similar reason as above, $\textbf{d}a^i \in \hat{\textbf{d}}$ and also $||\textbf{d}a^i|| \leq ||\textbf{d}|| \cdot ||a|| \cdot n^{i/2}$, therefore $\textbf{u}_i$ is a valid level-$i$ encoding of \textbf{d}.\\

Usually, the applications of Graded Encoding System require that a level-one representation of an element to be made public, without the possibility to recover a level-zero representation of that element. Thus, the process of generating $\textbf{u}_1$ requires a more extensive technique. That is because in the setting above, one can easily recover $\textbf{d}$ by simply dividing $\textbf{u}_1$ to \textbf{y} in $R_q$, which is unacceptable. \\

Therefore, every level-one encoding of an element is randomized, in order to prevent easy recovery of plain-text. The procedure is as follows: given $\textbf{d}$, a level-zero representation of an element, the first step is to extract an element $\textbf{r}$ from the spherical discrete Gaussian distribution $\mathcal{D}_{\bZ^m, \sigma^*}$, for a large enough $\sigma^*$. Then, the result is:

\begin{center}
	$\textbf{u}_1 = [\textbf{yd} + X^T\textbf{r}]_q = \Bigg[\textbf{yd} + \displaystyle{\sum_{i = 1}^{m} \textbf{x}_i \cdot r_i} \Bigg]_q = \Bigg[ \frac{a\textbf{d} + \sum_{i = 1}^{m} r_i \textbf{b}_i}{\zz} \Bigg]_q$.
\end{center}

Knowing that $b_i \in \hat{0}, \forall i\in \{1,2,..,m\}$ and that $a \in \hat{1}$, it easily follows that $a\textbf{d} + \sum_{i = 1}^{m} r_i \textbf{b}_i \in \hat{\textbf{d}}$. Also, the length of the numerator is upper-bounded by $\sigma^*\cdot$poly$(m,n)$. Also, if the parameters $\textbf{b}_i$ are chosen from a fairly wide enough spherical Gaussian distribution, then from \textbf{Theorem 4} it follows that the distribution of $B\textbf{r}$ is close to a wide ellipsoidal Gaussian. Hence, the distribution of $a\textbf{d} + B\textbf{r}$ is nearly independent of $a\textbf{d}$, so the encoding is truly randomized. 

\textbf{Remark 8.} \textit{Randomization may be performed at any level, not only the first one. Besides, other versions of Graded Encoding Schemes(e.g. \cite{CLT13}) include a procedure for randomization at level-one, denoted \textbf{reRand}. The current setting is more restrictive, but has the advantage that it realizes a randomization for every level-one encoding of an element, reducing the implementation errors due to negligence.}\\

%%%%%%%%%%%%%%%% Finished High Level Encoding %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Adding encodings:} \textbf{add}(params, $i, v_1, v_2$)

\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
\begin{center}
$\text{\textbf{add}(params,}i, v_1, v_2)$
\end{center}
\begin{algorithmic}[1]
\State \textbf{Output:} $[v_1+v_2]_q$.
\end{algorithmic}
\end{tcolorbox}

The addition in the current settings is a very simple operation, as it can be observed from the one-lined algorithm presented above. To verify the correctness of the addition algorithm, one may consider $v_1, v_2$, two level$-i$ encodings of the cosets $\widehat{e_1}$, respectively $\widehat{e_2}$. Therefore, there exist two elements $c_1 \in \widehat{e_1}, c_2\in\widehat{e_2}$ such that $v_1 = \big[ \frac{c_1}{\zz} \big]_q$ and $v_2 = \big[ \frac{c_2}{\zz} \big]_q$, and $c_1, c_2$ are short vectors. Adding the two encodings yields:
\begin{center}
	$[v_1+v_2]_q = \Big[ \big[ \frac{c_1}{\zz} \big]_q + \big[ \frac{c_2}{\zz}\big]_q \Big]_q = \big[\frac{c_1+c_2}{\zz}\big]_q$,
\end{center}
with $c_1+c_2 \in \widehat{e_1+e_2}$ and $c_1 + c_2$ a short vector in $R$. Thus, the exposed addition operation is correct.\\

\textbf{Remark 9.} \textit{Addition operation can be extended to support the summation of many elements simultaneously. It can be effortlessly seen that the size of the numerator remains small, even though addition is performed many times (e.g. a number of times polynomial in $n$)}.\\

%%%%%%%%%%%%%%%% Finished Addition %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Multiplying encodings: mul}(params, $v_i, v_j$).

\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		$\text{\textbf{mul}(params, } v_i, v_j)$
	\end{center}
	\begin{algorithmic}[1]
		\State \textbf{Output:} $[v_i \cdot v_j]_q$.
	\end{algorithmic}
\end{tcolorbox}

Multiplication operation is as simple as the addition one. The proof of correctness follows immediately.\\
Let $v_i$ be a level$-i$ encoding of a coset $\widehat{e_1}$ and let $v_j$ be a level$-j$ encoding of a coset $\widehat{e_2}$, with $0 \leq i, j$ and $i + j \leq k$. Then, using the properties of the construction, one may note that there must exist two vectors, $c_1 \in \widehat{e_1}, c_2 \in \widehat{e_2}$, such that $v_i = \big[ \frac{c_1}{\zz^i}\big]_q$ and  $v_j = \big[ \frac{c_2}{\zz^j}\big]_q$. Performing the multiplication of the encodings, as presented in the algorithm, the result is:

\begin{center}
	$[v_i \cdot v_j]_q = \Big[ \big[ \frac{c_1}{\zz^i}\big]_q \cdot \big[ \frac{c_2}{\zz^j}\big]_q\Big]_q = \big[ \frac{c_1 \cdot c_2}{\zz^{i+j}} \big]_q$,
\end{center}

with $c_1 \cdot c_2 \in \widehat{e_1 \cdot e_2}$, and $c_1 \cdot c_2$ a short vector in $R$ (thus unchanged in $R_q$). Hence, the multiplication operation exposed in the algorithm is correct.\\

\textbf{Remark 10.}  \textit{Usually, the applications of Graded Encoding Systems will require to multiply $k$ level-one encodings, thus the property stated at \textbf{Remark 8} also holds true for multiplication operation. As a result, it can be easily noted that the product of $k$ level-one encodings represents a level$-k$ encryption of an element.}\\

%%%%%%%%%%%%%%%% Finished Multiplication %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Zero testing: } isZero(params, \pzt, $u$)

\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		 \textbf{isZero}(params, \pzt, $u$)
	\end{center}
	\begin{algorithmic}[1]
		\If {$||$\pzt$\cdot u||_\infty \leq q^{\frac{3}{4}}$}
		\State Set $result = 1$
		\Else
		\State Set $result = 0$
		\EndIf
		\State \textbf{Output: } $result$
	\end{algorithmic}
\end{tcolorbox}


In order to test if two encodings represent the same element (obviously, on the same level), it is sufficient to substract them and compare to zero. The zero testing procedure involves a so-called zero-testing parameter and may be used only for level$-k$ encodings. However, despite the fact that the procedure always returns the correct answer for encodings of zero, it also may return (with negligible probability) a false answer for a non-zero encoding. \\

As presented in the instance generation algorithm, the zero-testing parameter is \pzt$=\big[\frac{\textbf{hz}^k}{\textbf{g}}\big]_q$, where $\textbf{h}\la \mathcal{D}_{\bZ^n, \sqrt{q}}$. Also, from the inherent structure of the construction it follows that there exists a short element $c$, such that $u = \big[\frac{c}{\textbf{z}^k}\big]_q$. To prove the \textit{general} faultlessness of the algorithm, it is required to remark that:
\begin{center}
	$w=$\pzt$\cdot u = \big[\frac{\textbf{hz}^k}{\textbf{g}}\big]_q \cdot \big[\frac{c}{\textbf{z}^k}\big]_q = \big[ \frac{\textbf{h}\cdot c}{\textbf{g}}\big]_q $.
\end{center}

\begin{itemize}
	\item If $u$ \textbf{is an encoding of zero}, then $c \in \hat{0}$, therefore $c \in \id$. Because $\id = \langle g \rangle$, it follows that $c = g \cdot \alpha$, for $\alpha \in R$. Thus, the element $\frac{c}{\textbf{g}}\in R$ is the same element as $c \cdot \textbf{g}^{-1} \in \mathbb{K}$. It follows that $||w||\leq ||\textbf{h}|| \cdot || c || \cdot ||\textbf{g}^{-1}|| \cdot \sqrt{n}^2$. Then, using \textbf{Theorem 3} for the case of choosing $\textbf{h} \la \mathcal{D}_{\bZ^n, \sqrt{q}}$, it can be easily noticed that $||\textbf{h}|| \leq \sqrt{q} \cdot \sqrt{n}$. Corroborating the last two results with the fact that $||\textbf{g}||$ is small (validated by the generation algorithm), it follows that:
	\begin{center}
		$||w|| \leq q^{\frac{1}{2}} \cdot \sqrt{n} \cdot q^{\frac{1}{8}} \cdot ||\textbf{g}^{-1}|| \cdot n  \leq q^{\frac{3}{4}}$.
	\end{center}

\item If $u$ \textbf{is an encoding of a non-zero coset}, then $c \notin \hat{0}$. In order to prove that the value $||w||$ is larger than $q^{\frac{3}{4}}$ with overwhelming probability, one more result must be settled below.\\


\textbf{Lemma 3 (Lemma 6.5, \cite{Gar15}).}  \textit{Let $w = \big[\frac{c\textbf{h}}{\textbf{g}}\big]_q$, with the properties: $||\textbf{g}w|| \leq \frac{q}{2}$ and $||c\textbf{h}|| \leq \frac{q}{2}$. If $\langle \textbf{g} \rangle$ is a prime ideal, then either $c$ or $\textbf{h}$ is in the ideal $\textbf{g}$. }\\

Using the same reason as in the first situation, it can be easily seen that $||\textbf{h}|| \leq \sqrt{q} \cdot \sqrt{n}$, with overwhelming probability. Then, because $||c|| \leq q^{\frac{1}{8}}$ (from the intrinsic structure of the construction), it follows that:
\begin{center}
	 $||c\cdot \textbf{h}|| \leq \sqrt{n} \cdot q ^{\frac{1}{2}} \cdot q^{\frac{1}{8}} \cdot \sqrt{n} = q^{\frac{5}{8}} \cdot n < \frac{q}{2}$. (1)
\end{center}

 \textbf{Supposing} that there exists $\epsilon > 0$ such that $||w|| \leq q^{1-\epsilon}$, then $||w\textbf{g}|| < q^{1-\epsilon} \cdot ||\textbf{g}|| \cdot \sqrt{n}$ and because $||g||$ is polynomial in $n$, it directly results that:
 \begin{center}
 	  $||w\textbf{g}|| < \frac{q}{2}$. (2)
 \end{center}
 Using the results (1) and (2) in collaboration with \textbf{Lemma 3}, it follows that either $c$ or $\textbf{h}$ is in the ideal $\langle \textbf{g} \rangle$, which is a \textbf{contradiction}, because $c \notin \hat{0}$ and $\textbf{h} \notin \id$. Then, for any $\epsilon > 0,$ $||w|| \geq q^{1-\epsilon}$, therefore $||w|| \geq q^{\frac{3}{4}}$.
\end{itemize}

\textbf{Remark 11.} \textit{The zero testing algorithm could have been written in a more condensed (and elegant) manner. However, in order to keep the same structure of the algorithm throughout the chapter, the current version was adopted.}\\

%%%%%%%%%%%%%%%% Finished Zero Testing %%%%%%%%%%%%%%%%%%%%%%%%%

\item \textbf{Extraction: } $r\la$ ext(params, \pzt, $u$)

\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		\textbf{ext}(params, \pzt, $u$)
	\end{center}
	\begin{algorithmic}[1]
		\State Set $M = \textbf{msbs}_{\frac{\log q}{4} - \lambda} \big([u \cdot $\pzt$]_q\big)$
		\Statex
		\State \textbf{Output:}  EXTRACT$_s(M)$
	\end{algorithmic}
\end{tcolorbox}

The extraction procedure is fairly simple. First, given $u,$ a valid level$-k$ representation of a coset, multiply it with {\pzt} (in $R_q$). Then extract the most significant $\frac{\log q}{4} - \lambda$ bits of \textit{each} of the coefficients of the result. Finally, apply a strong randomness extractor on the resulted bits. The algorithm was divided in two steps in order to stress its dual importance.\\

 The first step realizes a \textit{canonicalization} of cosets representation (the extraction procedure, applied to two different encodings of the same coset, must return the same result). On the other side, the second step performs a \textit{randomization} of the result, so that an external observer will not be capable to generate a valid standard representation of a desired coset. \\
 
 The correctness of the first step is further discussed. Let $\widehat{e_1}, \widehat{e_2} \in R/\id$ be two cosets, let $u_1 = \big[ \frac{c_1}{\zz^k} \big]_q$ and let $u_2 = \big[ \frac{c_2}{\zz^k} \big]_q$, with $c_1 \in \widehat{e_1}, c_2 \in \widehat{e_2}$.
 \begin{itemize}
 	\item If $\widehat{e_1} = \widehat{e_2}$, then $u_1$ and $u_2$ are \textbf{encodings of the same coset}. Then, using the results from \textit{zero-testing procedure}, it follows that $||$\pzt$u_1 - $\pzt$u_2|| = || $ \pzt $(u_1 - u_2)|| \leq q^{\frac{3}{4}}$. Therefore, with overwhelming probability, the most significant $\frac{\log q}{4}$ bits of every coefficient of (\pzt$u_1 - $\pzt$u_2$) are equal to 0, hence \pzt$u_1$ and \pzt$u_2$ have the same most significant ($\frac{\log q}{4} - \lambda$) bits for each coefficient. So, the same result is returned by the procedure for $u_1$ and $u_2$.
 	
 	\item If $\widehat{e_1} \neq \widehat{e_2}$, then $u_1$ and $u_2$ are \textbf{encodings of different cosets}. Therefore, it is known from \textit{zero-test procedure} that for every $\epsilon > 0$, $||$\pzt$(u_1-u_2)|| \geq q^{1 - \epsilon}$. It is now obvious that \pzt$u_1$ and \pzt$u_2$ do not have the same most significant ($\frac{\log q}{4} - \lambda$) bits for each coefficient, hence the procedure returns different results for $u_1$ and $u_2$.
 \end{itemize}



\textbf{Remark 12.} \textit{The element given as parameter to the Extract procedure must be a valid level$-k$ representation of a coset in $R/\id$. This information is used within the proof of correctness for the procedure, hence on other levels of encoding, the behavior is undefined.}

%%%%%%%%%%%%%%%% Finished Extraction Procedure %%%%%%%%%%%%%%%%%%%%%%%%%

\end{enumerate}

\section{Parameter constraints}

All of the above procedures rely on appropriate settings for the parameters, especially regarding the width of the Gaussian distributions. The constraints will be explained in-depth for every choice of parameter value.\\

\begin{itemize}
	\item $\bm{\sigma = \sqrt{\lambda n}}$. The parameter $\sigma$ defines the width of the first involved Gaussian, used for extraction of the generator $\textbf{g}$. The parameter must satisfy $\sigma \geq \eta_{2^{-\lambda}}$, so setting $\sigma = \sqrt{\lambda n}$ is safe. Note that, using \textbf{Theorem 3}, $||g|| \leq \sigma \sqrt{n} = n \sqrt{\lambda}$, with overwhelming probability.
	
	\item $\bm{\sigma' = \lambda n^{\frac{3}{2}}}$. In the paragraphs reserved for \textit{sampling} procedure, it was explained why $\sigma'$ should be lower bounded by $||g|| \cdot \sqrt{\lambda n}$. Using the upper bound for $||g||$, it follows that $\sigma' = \lambda n^{\frac{3}{2}}$ is a good parameter choice.
	
	\item $\bm{\sigma^* = 2^{\lambda}}$. Parameter $\sigma^*$ defines the width of the Gaussian distribution used to draw the randomization vector $\textbf{r}$ from \textit{higher level encoding} procedure. In order to apply \textbf{Theorem 4}, $\sigma^*$ must satisfy: $\sigma^* > poly(n,m,\lambda)$. Also, for the numerator of the randomized encoding to become independent of the numerator before the randomization, it suffices that $\sigma^* = 2^{\lambda}$. With this value for $\sigma^*$, a level-one encoding of a coset takes the form $\big[ \frac{c}{\zz} \big]_q$, with $||c|| \leq 2^\lambda \cdot poly(n)$.
	
	\item $\bm{q = 2^{8k\lambda} \cdot n^{O(k)}}$. Usually, applications of \textit{Graded Encoding Schemes} compute a level$-k$ encoding of a coset by multiplying $k$ level-one representations of cosets. Using the result above regarding the upper bounds for numerators of level-one encodings, it follows that the numerator of a level$-k$ representation will be upper bounded by: $(2^\lambda \cdot poly(n))^k$. Thus, in order for the product to be considered a valid encoding (which means that the size of numerator should not exceed $q^{\frac{1}{8}}$), it is necessary that: $(2^\lambda \cdot poly(n))^k \leq q^{\frac{1}{8}}$. Finally, by setting $q = 2^{8k\lambda} \cdot n^{O(k)}$ it is ensured that the value of $q$ is big enough for all the operations to be performed in a safe manner.
	
	\item $\bm{n > O(k\lambda^2)}$. For the scheme to assure a security level of $\lambda$, it is needed that $q < 2^{\frac{n}{\lambda}}$. Therefore, using the above restriction for $q$, it immediately results that $n > O(k \lambda^2)$.
	
	\item $\bm{m = O(n^2)}$. In order to apply \textbf{Theorem 4} during \textit{higher level encodings} proof of correctness, it is needed that $m > n \log q$. From the previous bounds for $q$ and $n$, it yields that $m = O(n^2)$.
\end{itemize}

\section{Hardness Assumptions}

This section is linked directly to \textbf{Subsection 1.4.2} by presenting the \textbf{GDL} and \textbf{GDDH} problems and their implications in the current settings.

\begin{enumerate}
	\item \textbf{Graded Discrete Logarithm (GDL).} \textit{It is said that the GDL problem is hard for a Graded Encoding System $GES$ if for all probabilistic polynomial running time algorithms, the discrete logarithm advantage of an adversary $\mathcal{A}$,}
	
	\begin{center}
		AdvDlog$_{GES, \mathcal{A}, k}(\lambda) \stackrel{\mathclap{\normalfont\mbox{def}}}{=} \Pr[\mathcal{A}(params,$ {\pzt}, $u) = a : (params, $ {\pzt}) $\la$ InstGen$(1^\lambda, 1^k), c \in R, u = \big[ \frac{c}{\zz^k} \big]_q, a\in \hat{c} $,
	\end{center}
	
	\textit{is negligible in $\lambda$.}\\
	
	\textbf{Remark 13.} \textit{The vigilant reader may note that the \textbf{GDL} problem is only defined for level$-k$ encodings of cosets. That is because if the element $u$ is a valid level$-i$ representation, with $1 \leq i < k$, the problem may become weak, as explained in \cite{GGH13}, Section 4.4}.

\end{enumerate}
	
In order to introduce the \textbf{GDDH} problem, it is required to define an algorithm that generates a \textbf{GDDH} instance, as the one presented in \cite{Gar15}, Section 7.1:\\

\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
	\begin{center}
		\textbf{genGDDH(params, \pzt)}
	\end{center}
	\begin{algorithmic}[1]
		\State Choose $\textbf{f} \la \mathcal{D}_{\bZ^n, \sigma}$. \Comment Level-zero encoding of a random coset
		\For {$i = 0$ to $k$}
		\State Choose $\textbf{e}_i \la \mathcal{D}_{\bZ^n, \sigma}$ \Comment Level-zero encoding of a random coset
		\State Choose $\textbf{r}_i \la \mathcal{D}_{\bZ^m, \sigma^*}$ \Comment Randomization vector
		\State Set $u_i = \big[\textbf{e}_i\textbf{y} + \sum_{j=1}^{m} r_j \xx_j \big]_q$ \Comment Randomized lvl-1 encoding of $\textbf{e}_i$
		\EndFor
		
		\State Set $u^* = \big[ \prod_{i = 1}^{k} u_ i\big] _q$  \Comment Level-$k$ encoding of last $k$ elements product
		\State Set $v = [\textbf{e}_0 \cdot u^*]$ \Comment Level-$k$ encoding of the $k+1$ elements
		\State Set $v' = [\textbf{f} \cdot u^*]$ \Comment Level$-k$ encoding of other $k+1$ elements
		\State \textbf{Output:} $(u_0, u_1, ..., u_k, v, v')$.
	\end{algorithmic}
\end{tcolorbox}

	
	\begin{enumerate}
	 \setcounter{enumi}{1}

	\item \textbf{Graded DDH (GDDH). } \textit{The GDDH problem is hard for a Graded Encoding System $GES$ if for any probabilistic polynomial running time algorithm $\mathcal{A}$, the advantage of $\mathcal{A}$ in distinguishing between the distributions:}
	
	\begin{center}
		(params, {\pzt}$, u_0, ... ,u_k, v$ ) and \\
		(params, {\pzt}$, u_0, ... ,u_k, v'$)
	\end{center}
	\textit{is negligible in $\lambda$, where $(params, $ {\pzt} $)\la$ InstGen$(1^\lambda, 1^k)$ and $(u_0, u_1, ..., u_k, v, v') =$ \textbf{genGDDH}(params, \pzt).}
\end{enumerate} 

\section{Applications}

Many of the applications of multilinear maps can be reproduced using Graded Encoding Schemes. Particularly, the system of Garg, Gentry and Halevi from 2013, presented in \cite{GGH13}, could easily be used as a replacement for multilinear maps in applications such as \textit{one-round $N$-way secret key exchange} protocol, presented in \cite{GGH13}, \textit{indistinguishability obfuscation} (which has the objective to make a computer program “unintelligible” while still preserving its functionality), depicted in \cite{GGH+13b} or \textit{Attribute-Based Encryption for general circuits}, detailed in \cite{GGH+13a}.\\

In the current section, only the first mentioned application will be illustrated. The \textit{one-round $N$-way key exchange} protocol is initially explained in \cite{BoS02}. Shortly, the protocol is used in order to allow $N$ users to set a common key, which is known only by the $N$ parties. This process involves two phases. In the first one, each user must broadcast a value to all the other users, and all broadcasts are realized concurrently. During the second phase, every party must collect the values broadcasted by the other users and compute the shared key. \\

From a high-level perspective, the $N-1$ Graded Encoding Systems may be utilized in the aforementioned protocol, as it follows. In the first phase, each of the users may extract a level-zero representation of a random coset (kept secret) and broadcast a randomized level-one encoding of it. During the second phase, each user multiplies all the $N-1$ public level-one representations of other users with his level-zero encoding, resulting in a level$-(N-1)$ cryptogram of the product of all $N$ cosets. Formally, the protocol consists of three algorithms, presented below:

\begin{enumerate}
	\item \textbf{Scheme setup: } 	(params, \pzt) $\la$ \textbf{Setup}($1^\lambda, 1^N$).
	
	\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
		\begin{center}
			\textbf{Setup}($1^\lambda, 1^N$)
		\end{center}
		\begin{algorithmic}[1]
			\State (params, \pzt) $\la$ \textbf{InstGen}($1^\lambda, 1^{N-1}$).
			\State \textbf{Output:} (params, \pzt).
		\end{algorithmic}
	\end{tcolorbox}

	The \textbf{Setup} algorithm is fairly simple, instantiating the parameters of the scheme with the parameters generated by \textit{InstGen} algorithm for $N-1$ GES. Also, it is required that the order of $R/\id$ is a large prime, or that all its prime divisors are large.\\
	
	\item \textbf{Parameter broadcast:} $w_i \la $\textbf{Publish}(params, \pzt, $i$).
	
		\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
		\begin{center}
			\textbf{Publish}(params, \pzt, $i$)
		\end{center}
		\begin{algorithmic}[1]
			\State Choose $\textbf{d}_i \la $ \textbf{samp} (params). \Comment Secret key of user $i$
			\State Set $w_i \la $ \textbf{enc} (params, 1, $\textbf{d}$). \Comment Level-one encoding of $\textbf{d}_i$
			\State \textbf{Output:} $w_i$.
		\end{algorithmic}
	\end{tcolorbox}

	The \textbf{Publish} procedure is the analogue of the mentioned first phase. Each user must extract a level-zero encoding of a random coset, using \textbf{samp} procedure of the GES instance, then return a randomized level-one representation of it.\\
	
	\item \textbf{Shared key reconstruction:} $sk \la$ \textbf{KeyGen}(params, \pzt, $i, \textbf{d}_i, \{w_j\}_{j \neq i}$).
	
			\begin{tcolorbox}[colframe=black,colback=white,arc=0pt,outer arc=0pt]
		\begin{center}
			\textbf{KeyGen}(params, \pzt, $i, \textbf{d}_i, \{w_j\}_{j \neq i}$)
		\end{center}
		\begin{algorithmic}[1]
			\State Set $v_i = \textbf{d}_i \cdot \prod_{j \neq i} w_j$. \Comment Level-$(N-1)$ encoding of all cosets product
			\Statex
			\State Set $sk \la $ \textbf{ext}(params, \pzt, $v_i$). \Comment Standard representation of element
		\end{algorithmic}
	\end{tcolorbox}

	The \textbf{KeyGen} procedure is the correspondent of the second phase. Therefore, each user must multiply the published parameters of the other users with his secret parameter, in order to generate a level$-(N-1)$ encoding of the product of all $N$ cosets. Finally, the key is represented by the canonical level$-(N-1)$ encoding of the result. 
\end{enumerate}

The correctness of the construction is obvious for the attentive user, who read the entire chapter. Also, the system is secure in the assumption that \textbf{GDDH} problem is hard for the GES instance.\\

As mentioned at the beginning of the section, the current GES setting has many other applications, and the interested lecturer may read the related papers, given as bibliography.



